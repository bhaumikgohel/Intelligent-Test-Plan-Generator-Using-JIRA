# ğŸš€ Intelligent Test Plan Generator

A full-stack web application that automates test plan creation by integrating JIRA ticket data with LLM-powered analysis using customizable templates.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)

## âœ¨ Features

- **ğŸ”Œ JIRA Integration**: Fetch ticket details directly from JIRA REST API v3
- **ğŸ¤– Dual LLM Support**: Use either Groq Cloud API or local Ollama models
- **ğŸ“„ Template Management**: Upload PDF templates to structure your test plans
- **âš¡ Real-time Generation**: Stream responses for faster feedback (optional)
- **ğŸ” Secure Storage**: API keys stored securely using OS keychain or encryption
- **ğŸ“± Responsive UI**: Clean, professional interface built with React + Tailwind
- **âŒ¨ï¸ Keyboard Shortcuts**: `Ctrl+Enter` to generate, quick actions for power users

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚     â”‚    Backend      â”‚     â”‚  External APIs  â”‚
â”‚  (React/Vite)   â”‚â”€â”€â”€â”€â–¶â”‚  (Express.js)   â”‚â”€â”€â”€â”€â–¶â”‚   JIRA REST     â”‚
â”‚   Port: 5173    â”‚     â”‚   Port: 3001    â”‚     â”‚   Groq API      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   Ollama        â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚   SQLite DB     â”‚
                                                â”‚  (local data)   â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ 
- npm or yarn
- (Optional) Ollama for local LLM support
- (Optional) JIRA API token
- (Optional) Groq API key

### Installation

1. **Clone and navigate to the project:**
   ```bash
   cd "AI Testplan Generator - JIRA"
   ```

2. **Install root dependencies:**
   ```bash
   npm install
   ```

3. **Install backend dependencies:**
   ```bash
   cd backend
   npm install
   cd ..
   ```

4. **Install frontend dependencies:**
   ```bash
   cd frontend
   npm install
   cd ..
   ```

5. **Initialize the database:**
   ```bash
   cd backend
   npm run db:init
   cd ..
   ```

6. **Configure environment variables (optional):**
   ```bash
   cp backend/.env.example backend/.env
   # Edit backend/.env with your settings
   ```

7. **Start the development servers:**
   ```bash
   npm run dev
   ```

   This starts:
   - Backend: http://localhost:3001
   - Frontend: http://localhost:5173

## ğŸ“– Usage Guide

### 1. Configure JIRA

1. Go to **Settings** â†’ **JIRA**
2. Enter your JIRA Base URL (e.g., `https://company.atlassian.net`)
3. Enter your username/email
4. Generate an API token from [Atlassian Account Settings](https://id.atlassian.com/manage-profile/security/api-tokens)
5. Click **Test Connection** to verify
6. Click **Save Configuration**

### 2. Configure LLM Provider

#### Option A: Groq Cloud (Recommended)
1. Get your API key from [Groq Console](https://console.groq.com)
2. Go to **Settings** â†’ **LLM**
3. Ensure "Use Local LLM" is **OFF**
4. Enter your Groq API key
5. Select a model from the available options:
   | Model | Description |
   |-------|-------------|
   | `llama-3.3-70b-versatile` | **Recommended** - Best quality |
   | `llama-3.1-70b-versatile` | Alternative 70B model |
   | `llama-3.1-8b-instant` | **Fastest** - Good for quick drafts |
   | `mixtral-8x7b-32768` | Mixture of Experts model |
   | `gemma-7b-it` | Google's Gemma model |
6. Adjust temperature if needed (0.7 is default)
7. Test and save

#### Option B: Ollama (Local)
1. Install Ollama from [ollama.com](https://ollama.com)
2. Pull a model: `ollama pull llama3`
3. Go to **Settings** â†’ **LLM**
4. Toggle "Use Local LLM" to **ON**
5. Click refresh to load available models
6. Select your model
7. Test and save

### 3. Upload Template (Optional)

1. Go to **Settings** â†’ **Templates**
2. Upload a PDF file containing your test plan structure
3. The system will extract the structure and use it for generation

### 4. Generate Test Plans

1. Go to **Generate** page
2. Enter a JIRA ticket ID (e.g., `SCRUM-5`)
3. Click **Fetch** to retrieve ticket details
4. Select a template
5. Click **Generate Test Plan** (or press `Ctrl+Enter`)
6. View, copy, or download the generated markdown

## ğŸ› ï¸ Development

### Project Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/        # API route handlers
â”‚   â”‚   â”œâ”€â”€ services/      # Business logic (JIRA, LLM, PDF)
â”‚   â”‚   â”œâ”€â”€ utils/         # Database, encryption, validators
â”‚   â”‚   â””â”€â”€ types/         # TypeScript types
â”‚   â”œâ”€â”€ data/              # SQLite database (auto-created)
â”‚   â””â”€â”€ templates/         # Uploaded PDF storage
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # UI components
â”‚   â”‚   â”œâ”€â”€ pages/         # Page components
â”‚   â”‚   â””â”€â”€ services/      # API client
â”‚   â””â”€â”€ public/
â””â”€â”€ template/              # Sample test plan PDF
```

### Available Scripts

| Command | Description |
|---------|-------------|
| `npm run dev` | Start both frontend and backend |
| `npm run dev:backend` | Start backend only |
| `npm run dev:frontend` | Start frontend only |
| `npm run build` | Build for production |
| `npm run start` | Start production server |

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/settings/jira` | GET/POST | JIRA configuration |
| `/api/settings/llm` | GET/POST | LLM configuration |
| `/api/settings/llm/models` | GET | List Ollama models |
| `/api/jira/fetch` | POST | Fetch JIRA ticket |
| `/api/jira/recent` | GET | Recent tickets |
| `/api/templates` | GET | List templates |
| `/api/templates/upload` | POST | Upload PDF |
| `/api/testplan/generate` | POST | Generate test plan |
| `/api/testplan/history` | GET | Generation history |

## ğŸ”’ Security

- API keys never stored in localStorage
- Credentials encrypted at rest using AES-256-GCM
- CORS restricted to localhost only
- Input validation for JIRA IDs and URLs
- PDF file size limited to 5MB

## ğŸ› Troubleshooting

### Backend Not Starting

**Error: `multer is not a function`**
- Fixed in latest version - imports updated to ES module syntax
- If still occurs, reinstall: `cd backend && rm -rf node_modules && npm install`

**Error: `ECONNREFUSED` when testing connections**
- Backend server is not running
- Start backend manually: `cd backend && npm run dev`
- Then start frontend in a new terminal: `cd frontend && npm run dev`

### JIRA Connection Failed

- Verify your JIRA base URL format (should be `https://domain.atlassian.net`)
- Ensure API token has correct permissions (read access to projects)
- Check if JIRA instance is accessible from your network
- Verify email address matches your Atlassian account

### Groq Connection Failed

**Error: `model has been decommissioned`**
- Some older models (like `llama3-70b-8192`) are deprecated
- Use updated models: `llama-3.3-70b-versatile` or `llama-3.1-70b-versatile`
- Select from dropdown in Settings â†’ LLM

**Other errors:**
- Verify API key is valid at [Groq Console](https://console.groq.com)
- Check Groq service status
- Ensure model name matches exactly

### Ollama Connection Failed

- Ensure Ollama is running: `ollama serve` or check system tray
- Verify Ollama is accessible at `http://localhost:11434`
- Check if model is downloaded: `ollama list`
- Download a model: `ollama pull llama3.1`

### Frontend Proxy Errors

**Error: `http proxy error: /api/...`**
- Backend is not running on port 3001
- Check if another app is using port 3001
- Start backend manually before frontend

## ğŸ“ Changelog

### v1.0.0 (2026-02-14)
- Initial release
- JIRA REST API v3 integration
- Groq Cloud LLM support with multiple models
- Ollama local LLM support
- PDF template upload and parsing
- Secure credential storage
- Markdown export (copy/download)

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- [shadcn/ui](https://ui.shadcn.com/) for beautiful UI components
- [Groq](https://groq.com/) for fast LLM inference
- [Ollama](https://ollama.com/) for local LLM support
- [Atlassian](https://www.atlassian.com/) for JIRA API
